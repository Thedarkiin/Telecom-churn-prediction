[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/downloads/release/python/)
[![CI](https://github.com/Thedarkiin/telecom-project/workflows/CI/badge.svg)](https://github.com/Thedarkiin/telecom-project/actions)

# Telecom Churn Prediction Pipeline

## Overview

A modular machine learning pipeline for predicting customer churn using the Kaggle Telco dataset (~7â€¯000 customers, 21 columns).  
The aim is to identify which subscribers are likely to leave and highlight the key factors behind their decisions.
A quick cool fact, telecom companies save up to 7 times more when keeping a subscribed customer rather than acquiring a new one.

> A business problem tackled through a clean ML structure.

---

## ğŸ“ Project Structure

```
churn/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ telecom_churn.csv      # Original dataset
â”‚   â””â”€â”€ cleaned_data.csv       # Preprocessed data
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ src.training           # Training logs
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ metrics/               # Model performance metrics
â”‚   â”‚   â”œâ”€â”€ all_metrics.csv
â”‚   â”‚   â”œâ”€â”€ univariate_odds_ratios.csv
â”‚   â”‚   â”œâ”€â”€ multivariate_odds_ratios.csv
â”‚   â”‚   â”œâ”€â”€ linearity_validation.csv
â”‚   â”‚   â”œâ”€â”€ optuna_study.csv
â”‚   â”‚   â””â”€â”€ *_confusion_matrix.png, *_roc_curve.png, *_pr_curve.png
â”‚   â”œâ”€â”€ predictions/           # Model predictions
â”‚   â”‚   â”œâ”€â”€ decision_tree_predictions.csv
â”‚   â”‚   â”œâ”€â”€ logistic_regression_predictions.csv
â”‚   â”‚   â””â”€â”€ xgboost_predictions.csv
â”‚   â”œâ”€â”€ explainability/        # SHAP analysis
â”‚   â”‚   â”œâ”€â”€ shap_importance.csv
â”‚   â”‚   â”œâ”€â”€ shap_summary_bar.png
â”‚   â”‚   â”œâ”€â”€ shap_summary_beeswarm.png
â”‚   â”‚   â””â”€â”€ importance_comparison.*
â”‚   â””â”€â”€ causal/                # Causal inference results
â”‚       â”œâ”€â”€ double_ml_results.csv
â”‚       â””â”€â”€ double_ml_interpretation.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Pipeline configuration (CV, tuning, etc.)
â”‚   â”œâ”€â”€ utils.py               # Logging and utilities
â”‚   â”œâ”€â”€ preprocessing.py       # Smart encoding & transformations
â”‚   â”œâ”€â”€ training.py            # Optuna hyperparameter optimization
â”‚   â”œâ”€â”€ evaluation.py          # Comprehensive metrics & visualizations
â”‚   â”œâ”€â”€ odds_ratio.py          # Univariate/multivariate odds ratios
â”‚   â”œâ”€â”€ double_ml.py           # Double ML causal inference
â”‚   â”œâ”€â”€ explainability.py      # SHAP/LIME interpretability
â”‚   â””â”€â”€ monte_carlo_lr.py      # Monte Carlo uncertainty quantification
â”‚
â”œâ”€â”€ pipeline.py
â”œâ”€â”€ diagram.svg
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


---

## ğŸ” Model Performance

The pipeline trains three models but **focuses on Logistic Regression** for interpretability and statistical rigor.

| Model               | Accuracy | Precision | Recall | F1â€‘score | ROC AUC | Threshold |
|--------------------|----------|-----------|--------|----------|---------|-----------|
| **Logistic Regression** | **0.7913** | **0.6299** | **0.5187** | **0.5689** | **0.7043** | 0.50 (F1) |
| XGBoost            | 0.7537   | 0.5252    | 0.7513 | 0.6183   | 0.7529  | 0.40      |
| Decision Tree      | 0.7260   | 0.4853    | 0.5294 | 0.5064   | 0.6633  | 0.45      |

**Why Logistic Regression?**
- **Interpretable**: Coefficients directly represent log-odds, convertible to odds ratios
- **Statistical validation**: Linearity assumptions tested via univariate analysis
- **Uncertainty quantification**: Monte Carlo simulation provides confidence intervals
- **Causal inference ready**: Compatible with Double ML framework

**Threshold Optimization**:
The pipeline computes optimal thresholds for both **recall** and **F1-score**:
- **Recall-optimized (0.35-0.40)**: Maximizes catching churners (fewer false negatives)
- **F1-optimized (0.50-0.55)**: Balances precision and recall (business optimal)

Higher thresholds reduce false positives (fewer non-churners incorrectly flagged), improving precision.

---

## ğŸ¯ Logistic Regression Insights

### Top Churn Risk Factors (Multivariate Odds Ratios)

The logistic regression model identifies key risk factors through odds ratios:

**High Risk (OR > 2.0)**:
- **Month-to-month contract**: 4-5Ã— higher churn risk vs. long-term contracts
- **No online security**: 2-3Ã— higher risk
- **Fiber optic internet**: 2-2.5Ã— higher risk (vs. DSL or no internet)
- **Electronic check payment**: 1.5-2Ã— higher risk

**Protective Factors (OR < 1.0)**:
- **Long tenure** (>24 months): 60-70% lower risk
- **Two-year contract**: 80-90% lower risk vs. month-to-month
- **Tech support subscription**: 40-50% lower risk

---

## ğŸ’¡ Why This Matters

Keeping a telecom customer costs less than acquiring a new one.  
This pipeline helps spot high-risk subscribers early and empowers the team to take action â€” whether it's offering discounts, improving support, or changing plans.

---

## ğŸ›  How to Run

>If you have anaconda do like me, i created a conda environnement so that i can install only the dependacies i want, aka needed for this specifc project.

```bash
git clone https://github.com/Thedarkiin/telecom-project.git
cd churn
pip install -r requirements.txt
python pipeline.py
```

**Outputs generated:**

- `results/metrics/all_metrics.csv`
- `results/metrics/feature_scores.csv`
- `results/metrics/xgboost_confusion_matrix.png`, etc.

---

## ğŸ“Š Visuals

### ğŸ”¹ Pipeline Architecture

![Pipeline Diagram](diagram.svg)

### ğŸ”¹ Confusion Matrix â€“ XGBoost

![XGBoost Confusion Matrix](results/metrics/xgboost_confusion_matrix.png)



---

## ğŸ“ Version Control

**Important**: The `results/` and `logs/` directories are gitignored as they contain generated files.
Only source code, configuration, and the original dataset (`data/telecom_churn.csv`) are tracked in version control.

To regenerate results:
```bash
python pipeline.py
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or pull request to suggest improvements.

---

## ğŸ“ About

Created by [Yassin Asermouh](https://www.linkedin.com/in/yassin-asermouh-984aa8249/).  
Built for learning, experimentation, and going beyond basic jupy notebooks.

**Data**: [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
